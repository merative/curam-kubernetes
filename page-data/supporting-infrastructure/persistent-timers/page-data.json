{"componentChunkName":"component---src-pages-supporting-infrastructure-persistent-timers-mdx","path":"/supporting-infrastructure/persistent-timers/","result":{"pageContext":{"frontmatter":{"title":"Persistent Timers","description":"Support and configuration of Liberty persistent timers"},"relativePagePath":"/supporting-infrastructure/persistent-timers.mdx","titleType":"page","MdxNode":{"id":"44c4ebef-127c-5cf3-bccf-5f17b287ec71","children":[],"parent":"667b4893-bf04-5f5b-a228-d837d57e3ed0","internal":{"content":"---\ntitle: Persistent Timers\ndescription: Support and configuration of Liberty persistent timers\n---\n\n## ![Cúram 8.0.0.0](https://img.shields.io/badge/-Cúram_8.0.0.0-green) Support for Liberty persistent timers\n\nLiberty persistent timers are configured by default to support the Cúram timer infrastructure.\n\nFor more information about Cúram timer infrastructure, see the *Cúram Server Developer's Guide*.\n\n<InlineNotification>\n\nCúram PDF documentation is available to download from [Cúram Support Docs](https://curam-spm-devops.github.io/wh-support-docs/spm/pdf-documentation/).\n\n</InlineNotification>\n\nThis configuration takes advantage of the Liberty capability, provided by release 20.0.0.1, to share a set of timer database tables across Liberty servers, which in our case run in Kubernetes pods.\n\nSharing database timer tables avoids the issue where automatic creation of timer tables that occurs at each and every server/pod start could pose a database limit risk.\nConsider a typical Cúram deployment of Curam, Rest, CitizenPortal, and Web Service applications with consumer and producer pods and three replicas.\nOn initial start that deployment would create 72 database tables.\nIt's not hard to imagine the many hundreds or thousands of tables that could be created over time as replicas are scaled up, pods restarted, and so forth.\n\nThe sharing of timer tables immediately reduces the number of timer tables required to a much more manageable number and, more importantly, keeps the number of tables bounded. This is achieved by grouping deployments into pod types.\nFor instance, one set of timer tables for all `apps-curam-producer` pods (one pod type), similarly for all `apps-curam-consumer` pods (another pod type), for all `apps-rest-producer` pods (another pod type), and so forth.\nThus, based on one set of tables per pod type the above example deployment requiring 72 tables is now fixed at 24 tables, regardless of how many replicas are started.\nThe pod type is derived at deployment time and exposed as an environment variable, which is read by the Liberty configuration: `${env.POD_TIMER_TYPE}`.\n\nThe out-of-the-box configuration of Liberty persistent timers should be adequate for most use cases.\nHowever, Helm Chart overrides are available for the most relevant Liberty settings that can be used to adjust behavior or performance depending upon your application, environment, etc.\nFor more information see the [Configuration Reference](/deployment/config-reference#liberty-runtime) and the [WebSphere Liberty documentation](https://www.ibm.com/docs/en/was-liberty/base?topic=applications-configuring-enterprise-javabeans-timer-service-persistent-timers).\n\n### Migrating from Cúram V7 to V8\n\nIf you are migrating to Cúram V8 you may cleanup the obsolete timer tables in your database.\nTo do this you need to be aware of how the timer tables were named previously.  \nBeing created uniquely for each pod means that the tables were named based on the pod name.\nThat is, the table names included the replicaset unique identifier (UUID), which is no longer used.\nFor example, a pod named `release-apps-curam-producer-76c8464b4d-9tzlx` would have mapped to a table name of  `EJBTIMER_RELEASE_APPS_CURAM_CONSUMER_76C8464B4D_9TZLX_PART`, which now maps to `EJBTIMER_RELEASE_APPS_CURAM_CONSUMER_PART`, etc.\n\nSince the old naming is no longer used those timer tables are obsolete once you migrate to Cúram V8 and the tables can safefly be removed.\nIn cleaning up obsolete tables you need to be careful to only identify obsolete tables.\nThe following SQL will generate `DROP` DDL statements that map specifically to the old table naming:\n\n<Tabs>\n\n<Tab label=\"Db2\">\n<Row>\n<Column>\n\n```shell\nselect concat('drop table ',strip(tabname)) from syscat.tables where tabname like 'EJBTIMER_%_APPS_%_%_%_%'\n```\n\n</Column>\n</Row>\n</Tab>\n\n<Tab label=\"Db2 for z/OS\">\n<Row>\n<Column>\n\n```shell\nselect concat('drop table ',strip(name))  || ';' from sysibm.systables where name like 'EJBTIMER_%_APPS_%_%_%_%';\n```\n\n</Column>\n</Row>\n</Tab>\n\n<Tab label=\"Oracle\">\n<Row>\n<Column>\n\n```shell\nselect 'DROP TABLE ' || OWNER || '.' || TABLE_NAME || ';' from SYS.ALL_TABLES  where TABLE_NAME LIKE 'EJBTIMER_%_APPS_%_%_%_%';\n```\n\n</Column>\n</Row>\n</Tab>\n\n</Tabs>\n\nBefore executing the `DROP` statements ensure that none of the pods identified by the table names are running.\n","type":"Mdx","contentDigest":"f451a57287104fcd16ed59fee05b9048","owner":"gatsby-plugin-mdx","counter":196},"frontmatter":{"title":"Persistent Timers","description":"Support and configuration of Liberty persistent timers"},"exports":{},"rawBody":"---\ntitle: Persistent Timers\ndescription: Support and configuration of Liberty persistent timers\n---\n\n## ![Cúram 8.0.0.0](https://img.shields.io/badge/-Cúram_8.0.0.0-green) Support for Liberty persistent timers\n\nLiberty persistent timers are configured by default to support the Cúram timer infrastructure.\n\nFor more information about Cúram timer infrastructure, see the *Cúram Server Developer's Guide*.\n\n<InlineNotification>\n\nCúram PDF documentation is available to download from [Cúram Support Docs](https://curam-spm-devops.github.io/wh-support-docs/spm/pdf-documentation/).\n\n</InlineNotification>\n\nThis configuration takes advantage of the Liberty capability, provided by release 20.0.0.1, to share a set of timer database tables across Liberty servers, which in our case run in Kubernetes pods.\n\nSharing database timer tables avoids the issue where automatic creation of timer tables that occurs at each and every server/pod start could pose a database limit risk.\nConsider a typical Cúram deployment of Curam, Rest, CitizenPortal, and Web Service applications with consumer and producer pods and three replicas.\nOn initial start that deployment would create 72 database tables.\nIt's not hard to imagine the many hundreds or thousands of tables that could be created over time as replicas are scaled up, pods restarted, and so forth.\n\nThe sharing of timer tables immediately reduces the number of timer tables required to a much more manageable number and, more importantly, keeps the number of tables bounded. This is achieved by grouping deployments into pod types.\nFor instance, one set of timer tables for all `apps-curam-producer` pods (one pod type), similarly for all `apps-curam-consumer` pods (another pod type), for all `apps-rest-producer` pods (another pod type), and so forth.\nThus, based on one set of tables per pod type the above example deployment requiring 72 tables is now fixed at 24 tables, regardless of how many replicas are started.\nThe pod type is derived at deployment time and exposed as an environment variable, which is read by the Liberty configuration: `${env.POD_TIMER_TYPE}`.\n\nThe out-of-the-box configuration of Liberty persistent timers should be adequate for most use cases.\nHowever, Helm Chart overrides are available for the most relevant Liberty settings that can be used to adjust behavior or performance depending upon your application, environment, etc.\nFor more information see the [Configuration Reference](/deployment/config-reference#liberty-runtime) and the [WebSphere Liberty documentation](https://www.ibm.com/docs/en/was-liberty/base?topic=applications-configuring-enterprise-javabeans-timer-service-persistent-timers).\n\n### Migrating from Cúram V7 to V8\n\nIf you are migrating to Cúram V8 you may cleanup the obsolete timer tables in your database.\nTo do this you need to be aware of how the timer tables were named previously.  \nBeing created uniquely for each pod means that the tables were named based on the pod name.\nThat is, the table names included the replicaset unique identifier (UUID), which is no longer used.\nFor example, a pod named `release-apps-curam-producer-76c8464b4d-9tzlx` would have mapped to a table name of  `EJBTIMER_RELEASE_APPS_CURAM_CONSUMER_76C8464B4D_9TZLX_PART`, which now maps to `EJBTIMER_RELEASE_APPS_CURAM_CONSUMER_PART`, etc.\n\nSince the old naming is no longer used those timer tables are obsolete once you migrate to Cúram V8 and the tables can safefly be removed.\nIn cleaning up obsolete tables you need to be careful to only identify obsolete tables.\nThe following SQL will generate `DROP` DDL statements that map specifically to the old table naming:\n\n<Tabs>\n\n<Tab label=\"Db2\">\n<Row>\n<Column>\n\n```shell\nselect concat('drop table ',strip(tabname)) from syscat.tables where tabname like 'EJBTIMER_%_APPS_%_%_%_%'\n```\n\n</Column>\n</Row>\n</Tab>\n\n<Tab label=\"Db2 for z/OS\">\n<Row>\n<Column>\n\n```shell\nselect concat('drop table ',strip(name))  || ';' from sysibm.systables where name like 'EJBTIMER_%_APPS_%_%_%_%';\n```\n\n</Column>\n</Row>\n</Tab>\n\n<Tab label=\"Oracle\">\n<Row>\n<Column>\n\n```shell\nselect 'DROP TABLE ' || OWNER || '.' || TABLE_NAME || ';' from SYS.ALL_TABLES  where TABLE_NAME LIKE 'EJBTIMER_%_APPS_%_%_%_%';\n```\n\n</Column>\n</Row>\n</Tab>\n\n</Tabs>\n\nBefore executing the `DROP` statements ensure that none of the pods identified by the table names are running.\n","fileAbsolutePath":"/home/runner/work/curam-kubernetes/curam-kubernetes/src/pages/supporting-infrastructure/persistent-timers.mdx"}}},"staticQueryHashes":["1364590287","137577622","2102389209","2456312558","2746626797","3018647132","3037994772","56986546","768070550"]}